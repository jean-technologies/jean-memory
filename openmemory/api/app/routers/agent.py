from fastapi import APIRouter, Depends, Body, BackgroundTasks
from pydantic import BaseModel
from app.auth import get_user
from app.models import User
from app.tools.orchestration import jean_memory
from app.context import user_id_var, client_name_var, background_tasks_var

router = APIRouter(
    prefix="/agent",
    tags=["Agent"],
)

class JeanMemoryRequest(BaseModel):
    user_message: str
    is_new_conversation: bool = False
    needs_context: bool = True

@router.post(
    "/jean_memory", 
    summary="Intelligent, Orchestrated Memory Interaction",
    response_description="A string containing the context generated by the agent, or a status message."
)
async def execute_jean_memory(
    request: JeanMemoryRequest,
    background_tasks: BackgroundTasks,
    user: User = Depends(get_user),
):
    """
    The primary, orchestrated entry point for all conversational interactions with Jean Memory.

    This single endpoint provides a powerful, agentic interface to the memory system. It intelligently
    engineers context, saves new information, and provides relevant background for your queries.

    - **user_message**: The user's complete message or question.
    - **is_new_conversation**: Set to `true` only for the very first message in a new chat session.
    - **needs_context**: Set to `false` for generic knowledge questions (e.g., 'what is science?'). 
                         Set to `true` for questions that would benefit from the user's personal context.
    """
    # Set context variables required by the underlying tool functions
    user_id_var.set(str(user.user_id))
    # Using 'api_client' to distinguish from MCP clients like 'claude' or 'chatgpt'
    client_name_var.set("api_client") 
    background_tasks_var.set(background_tasks)

    result = await jean_memory(
        user_message=request.user_message,
        is_new_conversation=request.is_new_conversation,
        needs_context=request.needs_context,
    )
    return {"response": result} 